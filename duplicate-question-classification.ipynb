{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Questions -duplicate data classification using sklearn and RNN","metadata":{"id":"brbZb8Z83dvh"}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2021-06-24T03:58:13.513424Z","iopub.execute_input":"2021-06-24T03:58:13.513760Z","iopub.status.idle":"2021-06-24T03:58:13.534751Z","shell.execute_reply.started":"2021-06-24T03:58:13.513728Z","shell.execute_reply":"2021-06-24T03:58:13.533884Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"/kaggle/input/quora-question-pairs/train.csv.zip\n/kaggle/input/quora-question-pairs/sample_submission.csv.zip\n/kaggle/input/quora-question-pairs/test.csv\n/kaggle/input/quora-question-pairs/test.csv.zip\n/kaggle/input/quora-duplicate/quora_duplicate_questions_new.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow.keras as keras\nfrom sklearn.metrics import mean_squared_error, confusion_matrix\nfrom zipfile import ZipFile as unzip\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-24T03:58:16.661877Z","iopub.execute_input":"2021-06-24T03:58:16.662266Z","iopub.status.idle":"2021-06-24T03:58:21.478793Z","shell.execute_reply.started":"2021-06-24T03:58:16.662236Z","shell.execute_reply":"2021-06-24T03:58:21.476389Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"train_path_zip = \"/kaggle/input/quora-question-pairs/train.csv.zip\"\nsub_path = \"/kaggle/input/quora-question-pairs/sample_submission.csv.zip\"\ntest_path = \"/kaggle/input/quora-question-pairs/test.csv\"\ntest_path_zip = \"/kaggle/input/quora-question-pairs/test.csv.zip\"\nvalidation_path = \"/kaggle/working/csv_quora_data_valid.csv\"\n\noutput_dir = \"/kaggle/working/\"\n\n# local_path = \"/kaggle/input/quora-duplicate/quora_duplicate_questions_new.csv\"","metadata":{"execution":{"iopub.status.busy":"2021-06-24T03:58:21.480742Z","iopub.execute_input":"2021-06-24T03:58:21.481281Z","iopub.status.idle":"2021-06-24T03:58:21.491898Z","shell.execute_reply.started":"2021-06-24T03:58:21.481246Z","shell.execute_reply":"2021-06-24T03:58:21.486188Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"datasets = pd.read_csv(train_path_zip)\n\ndatasets.dropna(inplace=True)\n\ntrain_dataset,valid_dataset  = datasets.iloc[:int(datasets.shape[0]*0.8),:],datasets.iloc[int(datasets.shape[0]*0.8):,:]\n\ntest_dataset = pd.read_csv(test_path_zip,low_memory=False)\n\n\nvalid_dataset.to_csv(validation_path)\ntrain_path = \"/kaggle/working/train.csv\"\ntrain_dataset.to_csv(train_path)\n# datasets.head(1)\n","metadata":{"id":"ScGqgBcm3nZ1","outputId":"1282bc9f-fa65-4036-f5f3-93268b56bb3e","execution":{"iopub.status.busy":"2021-06-23T11:27:59.815293Z","iopub.execute_input":"2021-06-23T11:27:59.815677Z","iopub.status.idle":"2021-06-23T11:28:18.657199Z","shell.execute_reply.started":"2021-06-23T11:27:59.815637Z","shell.execute_reply":"2021-06-23T11:28:18.656343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nprint(f\"Shape of train dataset:\\t{ datasets.shape }\\n\")\nprint(f\"Columns of datasets:\\t{ datasets.columns}\\n\")\nprint(f\"Validation dataset shape:\\t{valid_dataset.shape}\\n\")\nprint(f\"Training datasets\\t{train_dataset.shape}\\n\")\nprint(f\"First row Question1:\\n{datasets.iloc[0]['question1']}\\n\")\nprint(f\"First row Question2:\\n{datasets.iloc[0]['question2']}\\n\")\nprint(f\"Duplicate --0 or not --1:\\n{datasets.iloc[0]['is_duplicate']}\")","metadata":{"id":"vWYv-Zxiz5kA","outputId":"32b18c9c-bb0b-4f66-9e06-e49347ee5038","execution":{"iopub.status.busy":"2021-06-23T11:28:18.745054Z","iopub.execute_input":"2021-06-23T11:28:18.745406Z","iopub.status.idle":"2021-06-23T11:28:18.754473Z","shell.execute_reply.started":"2021-06-23T11:28:18.745368Z","shell.execute_reply":"2021-06-23T11:28:18.753236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf_datasets = tf.data.experimental.CsvDataset(train_path, [ tf.string,tf.string,tf.int32],header=True, select_cols=[4,5,6])\nvalid_tf_datasets = tf.data.experimental.CsvDataset(validation_path, [tf.string,tf.string,tf.int32],header=True, select_cols=[4,5,6])\ntest_tf_datasets = tf.data.experimental.CsvDataset(test_path, [tf.string,tf.string],header=True, select_cols=[1,2])\nvalid_tf_datasets, test_tf_datasets, tf_datasets","metadata":{"id":"yeX0kFsGFQCZ","outputId":"1c892a13-d4fd-4142-abbd-dcfeb547054d","execution":{"iopub.status.busy":"2021-06-23T11:28:18.757684Z","iopub.execute_input":"2021-06-23T11:28:18.758205Z","iopub.status.idle":"2021-06-23T11:28:20.585023Z","shell.execute_reply.started":"2021-06-23T11:28:18.758161Z","shell.execute_reply":"2021-06-23T11:28:20.584225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def print_data(data =tf_datasets):\n    for i in data.take(1):\n            print(i)\n    # pd.read_csv(\"./csv_quora_data.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-06-23T11:28:20.586651Z","iopub.execute_input":"2021-06-23T11:28:20.586898Z","iopub.status.idle":"2021-06-23T11:28:20.594652Z","shell.execute_reply.started":"2021-06-23T11:28:20.586873Z","shell.execute_reply":"2021-06-23T11:28:20.593367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Total  3 datasets in pandas and 3 in tensor\")\n\ndef get_all_pd_datasets():\n    print(f'All Datasets are:\\t train_dataset,valid_dataset, test_dataset')\n    return train_dataset,valid_dataset, test_dataset\n\ndef get_all_tf_datasets():\n    print(f'All Datasets are:\\ttf_datasets, valid_tf_datasets, test_tf_datasets')\n    return tf_datasets, valid_tf_datasets, test_tf_datasets\n","metadata":{"execution":{"iopub.status.busy":"2021-06-23T11:28:20.595954Z","iopub.execute_input":"2021-06-23T11:28:20.596396Z","iopub.status.idle":"2021-06-23T11:28:20.608877Z","shell.execute_reply.started":"2021-06-23T11:28:20.596285Z","shell.execute_reply":"2021-06-23T11:28:20.607919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SHUFFLE_SIZE = 10**5\nBATCH_SIZE = 64\nAUTOTUNE = tf.data.AUTOTUNE","metadata":{"execution":{"iopub.status.busy":"2021-06-23T11:28:20.610372Z","iopub.execute_input":"2021-06-23T11:28:20.610683Z","iopub.status.idle":"2021-06-23T11:28:20.616577Z","shell.execute_reply.started":"2021-06-23T11:28:20.610653Z","shell.execute_reply":"2021-06-23T11:28:20.61568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import regex as re\npat = re.compile(\"[.!@#$%^&*()><:;\"\"''?/\\*0-9]\")\n\ndef tf_preprocess(input_data):\n    input_data =input_data.map(lambda c,d,x: (tf.strings.lower(c),tf.strings.lower(d),x))\n    data = input_data.map(lambda a,c,d: (tf.strings.regex_replace(a,\"[.!@#$%^&*()><:;\"\"''?/\\*0-9]\",\"\"),tf.strings.regex_replace(c,\"[.!@#$%^&*()><:;\"\"''?/\\*0-9]\",\"\"),d))\n    data = data.cache().shuffle(SHUFFLE_SIZE).batch(BATCH_SIZE).prefetch(1)\n    return data\n\ndef tf_test_preprocess(input_data):\n    input_data =input_data.map(lambda c,d:( tf.strings.lower(c),tf.strings.lower(d)))\n    data = input_data.map(lambda a,c: (tf.strings.regex_replace(a,\"[.!@#$%^&*()><:;\"\"''?/\\*0-9]\",\"\"),tf.strings.regex_replace(c,\"[.!@#$%^&*()><:;\"\"''?/\\*0-9]\",\"\")))\n    data = data.batch(BATCH_SIZE).prefetch(1)    \n    return data\ntf_datasets= tf_datasets.apply(tf_preprocess)\n\nvalid_tf_datasets= valid_tf_datasets.apply(tf_preprocess)\ntest_tf_datasets = test_tf_datasets.apply(tf_test_preprocess)\n","metadata":{"id":"CQvGHA2A3rKq","execution":{"iopub.status.busy":"2021-06-23T11:28:20.618264Z","iopub.execute_input":"2021-06-23T11:28:20.618979Z","iopub.status.idle":"2021-06-23T11:28:20.942933Z","shell.execute_reply.started":"2021-06-23T11:28:20.618941Z","shell.execute_reply":"2021-06-23T11:28:20.942114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l = pd.read_csv(local_path)\nl.columns\n# tf_datasets\n# print_data(tf_datasets)","metadata":{"id":"BdpHlJEQbGTk","execution":{"iopub.status.busy":"2021-06-23T11:28:20.944528Z","iopub.execute_input":"2021-06-23T11:28:20.944892Z","iopub.status.idle":"2021-06-23T11:28:22.523042Z","shell.execute_reply.started":"2021-06-23T11:28:20.944855Z","shell.execute_reply":"2021-06-23T11:28:22.522259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nTo create vocab of most frequent words in datasets, here we first divide tf_datastes into datasets , each one for each \ncolumn questions. \nthen concatenate and using tensorflow text vectorization word dictionary\n\nwhere every is key and mapped to it's frequency. Here, only considering most frequent 1000 words\n'''\n\ntf_text_dataset = tf_datasets.map(lambda qid1,qid2,y: ((qid1,qid2),y))\ntf_text_dataset= tf_text_dataset.cache().shuffle(SHUFFLE_SIZE).prefetch(1)\n\n\ntf_text_new = tf_datasets.map(lambda qid1, qid2,y: (qid1))\ntf_text_new = tf_text_new.cache().prefetch(1)\n\ntf_text_new2 = tf_datasets.map(lambda qid1, qid2,y: (qid2))\ntf_text_new2 = tf_text_new2.cache().prefetch(1)\n","metadata":{"id":"YWbKUe-_f3pE","execution":{"iopub.status.busy":"2021-06-23T11:28:22.555804Z","iopub.execute_input":"2021-06-23T11:28:22.556442Z","iopub.status.idle":"2021-06-23T11:28:22.615738Z","shell.execute_reply.started":"2021-06-23T11:28:22.556339Z","shell.execute_reply":"2021-06-23T11:28:22.614922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_df = tf_text_new.concatenate(tf_text_new2)\ntext_df = text_df.cache().prefetch(1)\n","metadata":{"id":"WlQ3z4y-TNCD","execution":{"iopub.status.busy":"2021-06-23T11:28:22.616872Z","iopub.execute_input":"2021-06-23T11:28:22.617379Z","iopub.status.idle":"2021-06-23T11:28:22.622753Z","shell.execute_reply.started":"2021-06-23T11:28:22.617336Z","shell.execute_reply":"2021-06-23T11:28:22.621932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def print_data2(df=text_df):\n    for i in df.take(1):\n        if type(i)==tuple:\n            print(i[0].shape, i[0][0])\n        else:\n            print(len(i), i.shape, i.numpy()[0])\nprint_data2()","metadata":{"execution":{"iopub.status.busy":"2021-06-23T11:28:22.624033Z","iopub.execute_input":"2021-06-23T11:28:22.624623Z","iopub.status.idle":"2021-06-23T11:28:26.762482Z","shell.execute_reply.started":"2021-06-23T11:28:22.624588Z","shell.execute_reply":"2021-06-23T11:28:26.761575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"VOCAB_SIZE = 10000\nencoder = tf.keras.layers.experimental.preprocessing.TextVectorization(\n    max_tokens=VOCAB_SIZE)\nencoder.adapt(text_df.map(lambda text: text))","metadata":{"id":"gzIxj5cHXQDd","execution":{"iopub.status.busy":"2021-06-23T11:28:26.763752Z","iopub.execute_input":"2021-06-23T11:28:26.764271Z","iopub.status.idle":"2021-06-23T11:28:50.067847Z","shell.execute_reply.started":"2021-06-23T11:28:26.764232Z","shell.execute_reply":"2021-06-23T11:28:50.066924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab = np.array(encoder.get_vocabulary())\nfor example, label in tf_text_dataset.take(1):\n    print(\"text:\", example[0][0], example[1][0])\n    print()\n    print(\"label:\",label[0])\nencoded_example = encoder(example[0])[:3].numpy()\nencoded_example.shape","metadata":{"id":"IxFEUJYucPvv","outputId":"c80a4ba0-65c4-472f-ac1a-a0e90d149cb1","execution":{"iopub.status.busy":"2021-06-23T11:28:50.069607Z","iopub.execute_input":"2021-06-23T11:28:50.06995Z","iopub.status.idle":"2021-06-23T11:28:51.133733Z","shell.execute_reply.started":"2021-06-23T11:28:50.069912Z","shell.execute_reply":"2021-06-23T11:28:51.132966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for n in range(3):\n    print(\"Original: \", example[1][n].numpy())\n    print(\"Round-trip: \", \" \".join(vocab[encoded_example[n]]))\n    print()\n\n# (encoded_example).shape","metadata":{"id":"afbX_ntFhnkl","outputId":"eef8bd52-dde3-4785-c98f-2c116f68fa3b","execution":{"iopub.status.busy":"2021-06-23T11:28:51.135001Z","iopub.execute_input":"2021-06-23T11:28:51.135327Z","iopub.status.idle":"2021-06-23T11:28:51.144921Z","shell.execute_reply.started":"2021-06-23T11:28:51.135292Z","shell.execute_reply":"2021-06-23T11:28:51.143283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"print(f\"most_freq_words_dictionary limit 10\\t{vocab[:10]}\") ","metadata":{"execution":{"iopub.status.busy":"2021-06-23T11:28:51.149419Z","iopub.execute_input":"2021-06-23T11:28:51.149885Z","iopub.status.idle":"2021-06-23T11:28:51.154959Z","shell.execute_reply.started":"2021-06-23T11:28:51.149846Z","shell.execute_reply":"2021-06-23T11:28:51.154027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = keras.Sequential([\n                          encoder,\n                          keras.layers.Embedding(input_dim=len(encoder.get_vocabulary()),mask_zero=True,output_dim=64\n                                                 ),\n                          keras.layers.Bidirectional(keras.layers.LSTM(64)),\n                          keras.layers.Dense(64,activation=\"relu\"),\n                          keras.layers.Dense(1)\n])\n\nprint([layer.supports_masking for layer in model.layers])\n\n\nsample_text = ('what is name president'\n                'how do I become seo expert' )\npredictions = model.predict(np.array([sample_text]))\nprint(predictions[0])\n\n\npadding = \"the \" * 2000\npredictions = model.predict(np.array([sample_text, padding]))\nprint(predictions[0])","metadata":{"id":"lY3OX_e2jUHU","outputId":"1e7971c9-27df-4e30-dc12-4956e0e576d7","execution":{"iopub.status.busy":"2021-06-23T11:28:51.156685Z","iopub.execute_input":"2021-06-23T11:28:51.157045Z","iopub.status.idle":"2021-06-23T11:28:58.286497Z","shell.execute_reply.started":"2021-06-23T11:28:51.157009Z","shell.execute_reply":"2021-06-23T11:28:58.285662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nvalid_tf_dataset = valid_tf_datasets.map(lambda qid1,qid2,y: ((qid1,qid2),y))\nvalid_tf_dataset= valid_tf_dataset.cache().shuffle(SHUFFLE_SIZE).prefetch(1)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T11:28:58.28963Z","iopub.execute_input":"2021-06-23T11:28:58.289877Z","iopub.status.idle":"2021-06-23T11:28:58.316951Z","shell.execute_reply.started":"2021-06-23T11:28:58.289851Z","shell.execute_reply":"2021-06-23T11:28:58.316172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              optimizer=tf.keras.optimizers.Adam(1e-4),\n              metrics=['accuracy'])\nsave_model_path = \"/kaggle/working/model\"\nsaving_model = keras.callbacks.ModelCheckpoint(\n    save_model_path, monitor='val_loss', verbose=0, save_best_only=True,\n    save_weights_only=True, mode='auto', save_freq='epoch',\n    options=None\n)\nearly = keras.callbacks.EarlyStopping(patience=10)\nhistory = model.fit(tf_text_dataset, epochs=20,\n                    validation_data=valid_tf_dataset,callbacks=[saving_model,early],\n                    validation_steps=30)","metadata":{"id":"fSKpl0R_pe8G","outputId":"68ff8869-81a2-4722-e2f0-525a36261e50","execution":{"iopub.status.busy":"2021-06-23T12:49:18.738504Z","iopub.execute_input":"2021-06-23T12:49:18.738826Z","iopub.status.idle":"2021-06-23T13:11:29.394529Z","shell.execute_reply.started":"2021-06-23T12:49:18.738795Z","shell.execute_reply":"2021-06-23T13:11:29.393694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nmodel.load_weights(save_model_path)\n\nprint(f\"Model accuray\\t{model.evaluate(valid_tf_dataset)}\")\nprint(\"It is clear that it is higly overfitting and need of heavy regularization is required by our model\")\ndef plot_graphs(history, metric):\n    plt.plot(history.history[metric])\n    plt.plot(history.history['val_'+metric], '')\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(metric)\n    plt.legend([metric, 'val_'+metric])\n\nplot_graphs(history,'accuracy')","metadata":{"id":"0uZ4E4zzpzIf","outputId":"8cf77910-b7b1-4629-bd01-d8eef81ebbb9","execution":{"iopub.status.busy":"2021-06-23T13:22:56.859877Z","iopub.execute_input":"2021-06-23T13:22:56.86018Z","iopub.status.idle":"2021-06-23T13:23:04.879968Z","shell.execute_reply.started":"2021-06-23T13:22:56.86015Z","shell.execute_reply":"2021-06-23T13:23:04.879161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for (text1,text2),label in valid_tf_dataset.take(1):\n    print(len(text1), label.shape)\n    print(text1[0], text2[0], label[0])","metadata":{"id":"3VR2xzLZ1KzX","outputId":"7324c74d-bdba-4a62-ab16-0c9a65fa9465","execution":{"iopub.status.busy":"2021-06-23T13:23:10.309571Z","iopub.execute_input":"2021-06-23T13:23:10.309885Z","iopub.status.idle":"2021-06-23T13:23:10.331916Z","shell.execute_reply.started":"2021-06-23T13:23:10.309857Z","shell.execute_reply":"2021-06-23T13:23:10.331003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# , label\nm1 = (model.predict((text1,text2)) > 0.5).astype(\"int32\").reshape(1,-1)[0]; m2 = label\n\nprint(m1,m2)\nprint(f\"mean squred error of predictions\\t{mean_squared_error(m2,m1)}\")","metadata":{"id":"UMXdt8tY1u9-","outputId":"d4e68738-8b9f-4329-fca7-a83a3afe621f","execution":{"iopub.status.busy":"2021-06-23T13:24:45.741421Z","iopub.execute_input":"2021-06-23T13:24:45.741782Z","iopub.status.idle":"2021-06-23T13:24:45.796447Z","shell.execute_reply.started":"2021-06-23T13:24:45.741749Z","shell.execute_reply":"2021-06-23T13:24:45.795596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predictions or evalution on test dataset\ndef get_predictions_print(count=9, data=test_tf_datasets, label=None, print_stats=True):\n    print(f\"Predictions on only single bacth of size {BATCH_SIZE}:\\t{data}\\n\")\n    some_examples = next(data.as_numpy_iterator())\n    if label:\n        y_pred = (model.predict((some_examples[0],some_examples[1])) > 0.5).astype(\"int32\").reshape(1,-1)[0]\n    else:\n        y_pred = (model.predict(some_examples) > 0.5).astype(\"int32\").reshape(1,-1)[0]\n    if print_stats:\n        for i in range(count):\n            print(i+1, some_examples[0][i],'\\n')\n            print(i+1, some_examples[1][i],'\\n')\n            print(i+1,\"Predicted label:\", y_pred[i],'\\n')\n            if label:\n                print(f\"True label:\\t{some_examples[2][i]}\\n\")\n    if label:\n        m = mean_squared_error(some_examples[2], y_pred)\n        print(f\"Mean squared error:\\t{m}\")\n        return y_pred,m\n    return y_pred\n\nget_predictions_print()","metadata":{"id":"WCLgrdq-2fc2","outputId":"4d23884f-913b-4939-a9a6-aab3921955a1","execution":{"iopub.status.busy":"2021-06-23T13:54:48.432016Z","iopub.execute_input":"2021-06-23T13:54:48.432345Z","iopub.status.idle":"2021-06-23T13:54:48.527125Z","shell.execute_reply.started":"2021-06-23T13:54:48.432313Z","shell.execute_reply":"2021-06-23T13:54:48.526347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_predictions_print(data=valid_tf_datasets, label=True)\n\n\ntest_predictions = max(model.predict_proba(test_tf_dataset), axis=1)","metadata":{"id":"7byf7Ylg4VHB","execution":{"iopub.status.busy":"2021-06-23T13:54:57.979796Z","iopub.execute_input":"2021-06-23T13:54:57.980144Z","iopub.status.idle":"2021-06-23T13:54:58.12461Z","shell.execute_reply.started":"2021-06-23T13:54:57.980106Z","shell.execute_reply":"2021-06-23T13:54:58.123859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-06-24T03:46:10.879279Z","iopub.execute_input":"2021-06-24T03:46:10.879635Z","iopub.status.idle":"2021-06-24T03:46:11.750250Z","shell.execute_reply.started":"2021-06-24T03:46:10.879560Z","shell.execute_reply":"2021-06-24T03:46:11.749425Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-06-24T03:57:20.568785Z","iopub.execute_input":"2021-06-24T03:57:20.569114Z","iopub.status.idle":"2021-06-24T03:57:20.578857Z","shell.execute_reply.started":"2021-06-24T03:57:20.569083Z","shell.execute_reply":"2021-06-24T03:57:20.577986Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"1.0"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-06-23T15:08:42.865023Z","iopub.execute_input":"2021-06-23T15:08:42.865344Z","iopub.status.idle":"2021-06-23T15:08:42.870817Z","shell.execute_reply.started":"2021-06-23T15:08:42.865313Z","shell.execute_reply":"2021-06-23T15:08:42.869673Z"},"trusted":true},"execution_count":null,"outputs":[]}]}